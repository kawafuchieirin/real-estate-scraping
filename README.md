# Real Estate Scraping Project / ä¸å‹•ç”£ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

This project scrapes real estate data from major Japanese property portals for data analysis and visualization.

## ğŸ¯ Purpose / ç›®çš„

To gain practical experience in data engineering and data analysis through the complete process of scraping, analyzing, and visualizing real estate data.

ä¸å‹•ç”£ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‹ã‚‰åˆ†æãƒ»å¯è¦–åŒ–ã¾ã§ã‚’ä¸€é€šã‚Šå®Ÿæ–½ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ã‚­ãƒ«ã‚’å®Ÿè·µçš„ã«ç¿’å¾—ã™ã‚‹ã€‚

## ğŸ“‹ Features / æ©Ÿèƒ½

- Scrape property listings from major real estate portals (SUUMO, HOMES)
- Target: Tokyo 23 wards rental properties
- Data export in multiple formats (CSV, JSON, Parquet)
- Rate limiting and respectful scraping
- Comprehensive logging
- Modular architecture for easy extension

## ğŸš€ Quick Start / ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### Prerequisites / å‰ææ¡ä»¶

- Python 3.12+
- pip

### Installation / ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# Clone the repository
git clone https://github.com/kawafuchieirin/real-estate-scraping.git
cd real-estate-scraping

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage / åŸºæœ¬çš„ãªä½¿ã„æ–¹

```bash
# Run with default settings (first 3 areas, all property types)
python -m src.main

# Specify areas and property types
python -m src.main --areas 13113 13104 --property-types apartment

# Export as JSON
python -m src.main --export-format json

# Limit pages per search
python -m src.main --max-pages 3
```

## ğŸ“ Project Structure / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
real-estate-scraping/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/          # Configuration settings
â”‚   â”œâ”€â”€ scrapers/        # Website scrapers
â”‚   â”œâ”€â”€ models/          # Data models
â”‚   â”œâ”€â”€ utils/           # Utility functions
â”‚   â””â”€â”€ main.py          # Main entry point
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Raw scraped data
â”‚   â””â”€â”€ processed/      # Processed data
â”œâ”€â”€ logs/               # Log files
â”œâ”€â”€ tests/              # Test files
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md          # This file
```

## âš™ï¸ Configuration / è¨­å®š

The project uses the following default settings:

- **Target Areas**: Tokyo 23 wards (æ±äº¬23åŒº)
- **Property Types**: Apartments (ãƒãƒ³ã‚·ãƒ§ãƒ³), Apart (ã‚¢ãƒ‘ãƒ¼ãƒˆ), Houses (ä¸€æˆ¸å»ºã¦)
- **Rate Limiting**: 10 requests per 60 seconds
- **Export Formats**: CSV, JSON, Parquet

Settings can be modified in `src/config/settings.py` or via environment variables.

## ğŸ“Š Data Fields / ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰

Scraped properties include:

- Basic info: ID, URL, title, type
- Location: Prefecture, city, address, coordinates
- Price: Rent, management fee, deposit, key money
- Specifications: Floor plan, area, floor, building age
- Transportation: Nearest station, walking distance
- Metadata: Scraping timestamp

## ğŸ› ï¸ Development / é–‹ç™º

### Adding New Scrapers / æ–°ã—ã„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®è¿½åŠ 

1. Create a new file in `src/scrapers/`
2. Inherit from `BaseScraper`
3. Implement required methods
4. Add to the scrapers dictionary in `main.py`

### Running Tests / ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

```bash
pytest tests/
```

### Code Quality / ã‚³ãƒ¼ãƒ‰å“è³ª

```bash
# Format code
black src/

# Check linting
flake8 src/

# Type checking
mypy src/
```

## âš ï¸ Important Notes / é‡è¦ãªæ³¨æ„äº‹é …

1. **Respect robots.txt**: Always check and follow website scraping policies
2. **Rate Limiting**: Built-in rate limiting prevents overwhelming target servers
3. **Legal Compliance**: Ensure compliance with website terms of service
4. **Data Privacy**: Handle scraped data responsibly

## ğŸ—ºï¸ Roadmap / ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

- [x] Step 1: Basic scraping implementation
- [ ] Step 2: Full scraping implementation for multiple sites
- [ ] Step 3: Data cleaning and normalization
- [ ] Step 4: AWS integration (S3, Glue, Athena)
- [ ] Step 5: Data visualization (QuickSight)
- [ ] Step 6: Machine learning models

## ğŸ“„ License / ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

This project is for educational purposes. Please ensure compliance with all relevant laws and website terms of service when using.

## ğŸ¤ Contributing / ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

Contributions are welcome! Please feel free to submit a Pull Request
